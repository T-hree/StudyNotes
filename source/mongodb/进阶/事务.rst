===================
事务
===================


writeConcern
=================

什么是writeConcern
----------------------

writeConcern 决定一个写操作落到多少个节点上才算成功。
writeConcern的取值包括：

- 0: 发起写操作， 不关心是否成功；
- 1: 集群最大数据节点数： 写操作需要被复制到指定节点数才算成功
- majority: 写操作需要被复制到大多数节点上才算成功
发起写操作的程序将阻塞到写操作到达指定的节点数为止

默认行为
-----------

3 节点复制集 不作任何特别设定（默认值）：

 .. image:: ../../_static/mongodb/img/img_66.png
    :align: center

w: "majority"
--------------------

大多数节点确认模式

 .. image:: ../../_static/mongodb/img/img_67.png
    :align: center

w: "all"
---------------------

全部节点确认模式

 .. image:: ../../_static/mongodb/img/img_68.png
    :align: center

j: true
----------------

writeConcern 可以决定写操作到达多少个节点才算成功， journal则定义如何才算成功。
取值包括：

- true: 写操作落到journal文件才算成功；
- false: 写操作到达内存即算作成功。

writeConcern 的意义
-------------------------

对于5个节点的复制集来说，写落到多少个几点上才算是安全的？

- 1
- 2
- 3  √
- 4  √
- 5  √
- majority  √

writeConcern 实验
----------------------

*在复制集测试writeConcern参数*
::

    db.test.insert({count:1}, {writeConcern:{w:"majority"}})
    db.test.insert({count:1}, {writeConcern:{w:3}})
    db.test.insert({count:1}, {writeConcern:{w:4}})

*配置延迟节点， 模拟网络延迟（复制延迟）*
::

    conf=rs.conf()
    conf.members[2].secondaryDelaySecs = 10 （延迟节点  单位秒）
    conf.members[2].priority = 0
    rs.reconfig(conf)

*观察复制集延迟下的写入， 以及timeout参数*
::

    db.test.insert({count:1},{writeConcern:{w:3}})
    # 等待10秒后 返回结果 写入完成
    db.test.insert({count:1},{writeConcern:{w:3, wtimeout:3000}})
    # 等待3秒后， 返回结果：
    WriteResult({
            "nInserted" : 1,
            "writeConcernError" : {
                    "code" : 64,
                    "codeName" : "WriteConcernFailed",
                    "errmsg" : "waiting for replication timed out",
                    "errInfo" : {
                            "wtimeout" : true,
                            "writeConcern" : {
                                    "w" : 3,
                                    "wtimeout" : 3000,
                                    "provenance" : "clientSupplied"
                            }
                    }
            }
    })
    # "nInserted" : 1,表示 写入成功了， 后面的error 表示  某些节点还没有完成  需要更新义务场景进行处理

注意事项
-----------------

- 虽然多于半数的writeConcern 都是安全的， 但通常只会设置majority， 因为这是等待些人延迟时间最短的选择；
- 不要设置 writeConcern 等于总节点数， 因为一旦有一个节点故障， 所有写操作都将失败；
- writeConcern 虽然会增加 写操作延迟时间， 但并不会显著增加集群压力， 应此无论是否等待，写操作最终都会复制到所有节点上。 设置writConcern只是让写操作等待复制后在返回而已；
- 应对重要数据 应用 `` {w:"majority"}`` 普通数据可以应用 ``{w:1}`` 以确保最佳性能


读事务
===============

综述
-------------

在读取数据的过程中我们需要关注以下两个问题：

- 从哪里读？ 关注数据节点 位置
- 什么样的数据可以读？ 关注数据的隔离性
| 第一个问题是由readPreference来解决
| 第二个问题则是由 readConcern来解决


什么是readPreference
---------------------------

readPreference决定使用哪一个节点来满足正在发起的读请求。可选值包括：

- primary: 只选择主节点
- primaryPreferred： 优先选择主节点， 如果不可用则选择从节点
- secondary: 只选择从节点；
- secondaryPreferred: 优先选择从节点，如果从节点不可用则选择主节点
- nearest: 选择最近的节点

readPreference场景举例
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

- 用户下订单马上将用户订单详情页 ---- primary/primaryPreferred. 因为此时从节点可能还没有复制到新订单
- 用户查询自己下过的订单 ---- secondary/secondaryPreferred. 查询历史订单对时效性通常没有太高的要求
- 生成报表 ---- secondary 报表对是时效性要求不搞， 但资源需求大， 可以在从节点单独处理， 避免对线上用户造成影响
- 将用户上传的图片分发到全世界， 让各地用户能够就近读取 ---- nearest  每个地区的应用选择最近的节点读取数据


readPreference 与 Tag
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

readPreference只能控制使用一类节点。Tag则可以将节点选择控制到一个或多个节点。考虑一下场景：

- 一个  5个节点的复制集
- 3个节点硬件较好， 专用于服务线上客户
- 2个节点硬件较差， 专用于生成报表
可以使用Tag来打到这样的控制目的：

- 为3个较好的节点打上 {purpose:"online"}
- 为2个较差的节点打上 {purpose: "analyse"}
- 在线应用读取时指定 online, 报表读取时指定 analyse


readPreference 配置
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

通过MongoDB的连接串参数：
::

    mongodb://host1:27017,host2:27017,host3:27017/?replicaSet=rs#readPreference=secondary


通过MongoDB驱动程序API：
::

    MongodbCollection.withReadPreference(ReadPreference readPref)

Mongo Shell:
::

    db.collection.find({}).readPref("secondary")

readPreference实验：从节点读
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 主节点写入{x:1}, 观察该条数据在各个节点均可见
::

    rs0:PRIMARY> db.test.insert({count:1})
    WriteResult({ "nInserted" : 1 })

- 在两个从节点分别执行db.fsyncLock() 来锁定写入(同步)
::

    rs0:SECONDARY> db.fsyncLock()
    {
            "info" : "now locked against writes, use db.fsyncUnlock() to unlock",
            "lockCount" : NumberLong(1),
            "seeAlso" : "http://dochub.mongodb.org/core/fsynccommand",
            "ok" : 1,
            "$clusterTime" : {
                    "clusterTime" : Timestamp(1649854602, 1),
                    "signature" : {
                            "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),
                            "keyId" : NumberLong(0)
                    }
            },
            "operationTime" : Timestamp(1649854592, 1)
    }

- 主节点写入{x:2}
    - db.test.find({x:2})
    ::

        rs0:PRIMARY> db.test.find()
        { "_id" : ObjectId("6256cd35262cf4ed07e4bdc6"), "x" : 1 }

    - db.test.find({a:123}).readPref("secondary")  # 指定在从节点读
    ::

        rs0:PRIMARY> db.test.find().readPref('secondary')
        { "_id" : ObjectId("6256cd35262cf4ed07e4bdc6"), "x" : 1 }
        { "_id" : ObjectId("6256cd9d262cf4ed07e4bdc7"), "x" : 2 }

- 解除从节点锁定db.fsyncUnlock()
    - db.test.find({a:123}).readPref("secondary")
    ::

        rs0:PRIMARY> db.test.find().readPref('secondary')
        { "_id" : ObjectId("6256cd35262cf4ed07e4bdc6"), "x" : 1 }
        { "_id" : ObjectId("6256cd9d262cf4ed07e4bdc7"), "x" : 2 }

注意事项
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

- 指定readPreference时也应注意高可用的问题。 例如将readPreference指定primary， 则发生故障转移不存在primary期间将没有节点可读。如果业务允许， 则应选择primaryPreferred
- 使用Tag是也会遇到同样的问题， 如果只有一个节点拥有一个特定Tag， 则在这个节点失效时 将无节点可读。 这在有时候是期望的结果， 有时候不是。例如：
    - 如果报表使用的节点失效， 即使不生成报表， 通常也不希望将报表负载转移到其他节点上，此时只有一个节点有报表Tag是合理的选择
    - 如果线上节点失效， 通常希望有代替节点， 所以因该保持多个节点有同样的Tag
- Tag 有事需要与优先级、 选举权综合考虑， 例如做报表的节点通常不会希望他成为主节点， 则优先级因为0


什么是readConcern？
-----------------------------

在readPreference选择了指定的节点后， readConcern决定这个节点上的数据那些是可读的， 类似于关系数据库的隔离级别。可选值包括：

- available: 读取所有可用的数据；
- local: 读取所有可用且属于当前分片的数据
- majority: 读取大多数节点上提交完成的数据；
- linearizable: 可线性化读取文档；
- snapshot: 读取最近快照中的数据；

readConcern: local和available
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

在复制集中local和available是没有区别的。 两者的区别主要体现在分片集上。 考虑以下场景：

- 一个 chunk x 正在从 shard1 向 shard2 迁移；
- 整个迁移过程中chunk x 中的部分数据会在shard1 和 shard2 中同时存在， 但源分片shard1任然是chunk x 的负责方：
    - 所有对chunk x 的读写操作任然进入 shard1
    - config 中记录的信息 chunk x 任然属于 shard1
- 此时如果读 shard2， 则会体现出 local 和available 的区别
    - local  只取因该由shard2 负责的数据 （不包括x）
    - available  shard 2 上有什么就读什么（包括x）

 .. image:: ../../_static/mongodb/img/img_69.png
    :align: center

注意事项：
"""""""""""""""""""

- 虽然看上去总是应该选择local， 但毕竟对结果集进行过滤会造成额外消耗。 在一些无关紧要的场景（例如统计）下， 也可以考虑available
- Mongodb <= 3.6 不支持对从节点使用{readConcern:"local"}
- 从主节点读取数据时默认readConcern是local， 从从节点读取数据是 默认readConcern是 available（向前兼容原因）

readConcern: majority
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

只读取大多数节点上都提交了的数。 考虑如下场景：

- 集合中原有文档{x:0}
- 将x值更新为1

 .. image:: ../../_static/mongodb/img/img_70.png
    :align: center

如果在各节点上应用{readConcern: majority}来读取数据：

 .. image:: ../../_static/mongodb/img/img_71.png
    :align: center

readConcern: majority 的实现方式
""""""""""""""""""""""""""""""""""""""""""

考虑t3时刻的Secondary1， 此时：

- 对于要去 majority的读操作， 他将返回x = 0
- 对应不要去majority的读操作， 他将返回x = 1

 .. image:: ../../_static/mongodb/img/img_72.png
    :align: center

| 如何实现？
| 节点上维护多个x版本， MVCC机制 MongoDB通过维护多个快照来链接不同的版本：

- 每个被大多数节点确认过的版本都将是一个快照
- 快照持续到没有人使用为止才被删除

实验： readConcern: 'majority' vs 'local'
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

- 安装3节点复制集
- 注意配置文件内server参数 enableMajorityReadConcern
- 将复制集中的两个从节点使用db.fsyncLock()锁住写入（模拟同步延迟）

readConcern 验证
"""""""""""""""""""""""

- db.test.insert({a:1})
- db.test.find().readConcern('local')
- db.test.find()/readConcern('majority')
- 在某一个从节点上执行db.fsyncUnlock()
- 结论：
    - 使用local参数， 则可以直接查询到写入数据
    - 使用majority， 只能查询到已经被多数节点确认过的数据
    - update 与 remove 与上同理。

readConcern: majority 与 脏读
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

MongoDB中的回滚：

- 写操作打到大多数节点之前都是不安全的， 一旦主节点崩溃， 而从节点还没复制到该次操作，刚才的写操作就丢失了
- 把一次写操作视为一个事务， 从事务的角度， 可以任务事务被回滚了

| 所以从分布式系统的角度来看， 事务的提交被提升到了分布式集群的多个节点级别的“提交” ， 而不再是单个节点上的“提交”
| 在可能发生回滚的前提下考虑脏读问题：

- 如果在一次写操作打到大多数节点前读取了这个写操作， 然后因为系统故障该操作回滚了， 则发生了脏读问题
使用{readConcern:"majority"}可以有效避免脏读

readConcern: 如何实现安全的读写分离
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

考虑如下场景：
::

    向主节点写入一条数据
    立刻从主节点读取这条数据

如何保证自己能够读到刚刚写入的数据？

下述方式可能读不到刚写入的订单：
::

    db.orders.insert({oid:101, sku:"kite", q:1})
    db.orders.find({oid:101}).readPref('secondary')

使用writeConcern + readConcern majority 来解决:
::

     db.orders.insert({oid:101, sku:"kite", q:1}, {writeConcern:{w:"majority"}})
     db.orders.find({oid:101}).readPref('secondary').readConcern("majority")

小测试
"""""""""""""""""""""""""

| readConcern 主要关注读的隔离性， ACID中的Isolation， 但是是分布式数据库里面特有的概念
| readConcern: majority对应于事务中隔离级别中的哪一级？

- Read Uncommitted
- Read Committed  √
- Repeatable Read
- Seriazable

readConcern: linearizable
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
只读取大多数节点确认过的数据。 和 majority最大差别是保证绝对的操作线性顺序 - 在写操作自然时间后面的发生的读， 一定可以读到之前的写：

- 只对读取单个文档时有效
- 可能导致非常慢的读， 因此总是建议配合使用maxTimeMS

 .. image:: ../../_static/mongodb/img/img_73.png
    :align: center

readConcern: snapshot
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

{readConcern:'snapshot'} 只在多文档事务中生效， 讲一个事务的readConcern设置为snapshot ， 保证在事务中的读：

- 不出现脏读
- 不出现不可重复读
- 不出现幻读

 因为所有的读都将使用同一个快照， 直到事务提交为止 该快照才被释放

多文档事务
=================

综述
----------------

| Mongodb虽然已经在4.2开始全面支持了多文档事务，但并不代表大家已改毫无节制的使用他，相反， 对事务的使用原则因该是：能不用尽量不用
| 通过合理地设计文档模型， 可以避免绝大部分使用事务的必要性
| 为什么？ ===>>>  事务 = 锁 ， 节点协调， 额外开销， 性能影响

MongoBD ACID 多文档事务支持
-------------------------------------

 .. image:: ../../_static/mongodb/img/img_74.png
    :align: center

使用方法
^^^^^^^^^^^^^^^^^^

MongoDB多文档事务的使用方式与关系数据库非常相似：
::

    try(ClientSession clientSession = client.startSession()){
        clientSession.startTransaction();
        collection.insertOne(clientSession, docOne);
        collection.insertOne(clientSession, docTwo);
        clientSession.commitTransaction();
    }

事务隔离级别
------------------

- 事务完成前， *事务外的操作* 对改事务所做的修改不可访问
- 如果事务内使用{readConcern: 'snapshot'}, 则可以打到可重复去 Repeatable Read


实验：启用事务后的隔离性
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

::

    rs0:PRIMARY> db.tx.find()
    { "_id" : ObjectId("62578f3e1c7fac7ad116fe36"), "x" : 1 }
    { "_id" : ObjectId("62578f601c7fac7ad116fe37"), "x" : 2 }
    rs0:PRIMARY> var session = db.getMongo().startSession()  # 生成事务对象
    rs0:PRIMARY> session.startTransaction()  # 开启事务
    rs0:PRIMARY> var coll = session.getDatabase('test').getCollection('tx')  # 获取文档对象
    rs0:PRIMARY> coll.update({x:1}, {$set:{y:1}})  # 事务中修改
    WriteResult({ "nMatched" : 1, "nUpserted" : 0, "nModified" : 1 })
    rs0:PRIMARY> coll.find()  # 事务中查询
    { "_id" : ObjectId("62578f3e1c7fac7ad116fe36"), "x" : 1, "y" : 1 }
    { "_id" : ObjectId("62578f601c7fac7ad116fe37"), "x" : 2 }
    rs0:PRIMARY> db.tx.find()  # 事务外查询
    { "_id" : ObjectId("62578f3e1c7fac7ad116fe36"), "x" : 1 }
    { "_id" : ObjectId("62578f601c7fac7ad116fe37"), "x" : 2 }
    rs0:PRIMARY> session.commitTransaction()  # 提交事务
    rs0:PRIMARY> db.tx.find()
    { "_id" : ObjectId("62578f3e1c7fac7ad116fe36"), "x" : 1, "y" : 1 }
    { "_id" : ObjectId("62578f601c7fac7ad116fe37"), "x" : 2 }


实验： 可重复读 Repeatable Read
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

::

    rs0:PRIMARY> var session = db.getMongo().startSession()
    rs0:PRIMARY> session.startTransaction({radConcern:{level:'snapshot'},writeConcern:{w:'majority'}})
    rs0:PRIMARY> coll = session.getDatabase('test').getCollection('tx')
    test.tx
    rs0:PRIMARY> coll.find()
    { "_id" : ObjectId("62578f3e1c7fac7ad116fe36"), "x" : 1, "y" : 1 }
    { "_id" : ObjectId("62578f601c7fac7ad116fe37"), "x" : 2 }
    rs0:PRIMARY> db.tx.updateOne({x:1}, {$set:{y:2}})
    { "acknowledged" : true, "matchedCount" : 1, "modifiedCount" : 1 }
    rs0:PRIMARY> db.tx.find()
    { "_id" : ObjectId("62578f3e1c7fac7ad116fe36"), "x" : 1, "y" : 2 }
    { "_id" : ObjectId("62578f601c7fac7ad116fe37"), "x" : 2 }
    rs0:PRIMARY> coll.find()
    { "_id" : ObjectId("62578f3e1c7fac7ad116fe36"), "x" : 1, "y" : 1 }
    { "_id" : ObjectId("62578f601c7fac7ad116fe37"), "x" : 2 }
    rs0:PRIMARY> session.abortTransaction()


事务写机制
------------------

MongoDB 的事务错误处理机制不同于关系性数据库：

- 当一个事务开始后， 如果事务要修改的文档在事务外部被修改过， 则事务修改这个文档时会触发 Abort 错误， 因为此时的修改冲突了；
- 这种情况下， 只需要简单的重做事务就可以了
- 如果一个事务已经开始修改一个文档， 在事务以外尝试修改用一个文档， 则事务以外的修改会等事务完成才能继续进行（write-wait.md实验)

实验： 写冲突
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

继续使用上个实验的tx集合

开两个mongo shell 均执行下述语句：
::

    var session = db.getMongo().startSession()
    session.startTransaction({
        readConcern:{level:'snapshot'},
        writeConcern:{w:'majority'}
    })
    var coll = session.getDatabase('test').getCollection('tx')

窗口一先进行update:
::

    coll.updateOne({x:1},{$set:{y:1}})
    { "acknowledged" : true, "matchedCount" : 1, "modifiedCount" : 1 }

窗口二在进行update 会报错:
::

    rs0:PRIMARY> coll.updateOne({x:1},{$set:{y:1}})
    uncaught exception: WriteCommandError({
            "errorLabels" : [
                    "TransientTransactionError"
            ],
            "ok" : 0,
            "errmsg" : "WriteConflict error: this operation conflicted with another operation. Please retry your operation or multi-document transaction.",
            "code" : 112,
            "codeName" : "WriteConflict",
            "$clusterTime" : {
                    "clusterTime" : Timestamp(1649919215, 1),
                    "signature" : {
                            "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),
                            "keyId" : NumberLong(0)
                    }
            },
            "operationTime" : Timestamp(1649919215, 1)
    }) :
    WriteCommandError({
            "errorLabels" : [
                    "TransientTransactionError"
            ],
            "ok" : 0,
            "errmsg" : "WriteConflict error: this operation conflicted with another operation. Please retry your operation or multi-document transaction.",
            "code" : 112,
            "codeName" : "WriteConflict",
            "$clusterTime" : {
                    "clusterTime" : Timestamp(1649919215, 1),
                    "signature" : {
                            "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),
                            "keyId" : NumberLong(0)
                    }
            },
            "operationTime" : Timestamp(1649919215, 1)
    })

窗口一将事务提交：
::

    session.commitTransaction()

窗口二再次update也会报错， 需要重启事务:
::

    rs0:PRIMARY> session.abortTransaction()
    rs0:PRIMARY> session.startTransaction({readConcern:{level:'snapshot'},writeConcern:{w:'majority'}})
    rs0:PRIMARY> var coll = session.getDatabase('test').getCollection('tx')
    rs0:PRIMARY> coll.updateOne({x:1},{$set:{y:2}})
    { "acknowledged" : true, "matchedCount" : 1, "modifiedCount" : 1 }
    # 此时就不会报错
    # 提交


实验:写冲突（续)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

窗口1： 第一个事务，正常提交： `coll.updateOne({x:1},{$set:{y:1}})`
窗口2： 另一个事务更新同一条数据，异常： `coll.updateOne({x:1},{$set:{y:2}})`
窗口3： 事务外更新，会一直等待 直到第一个事务 commit后立即执行： `coll.updateOne({x:1},{$set:{y:3}})`

注意事项
------------------------

- 可以实现和关系型数据库类似的事务常见
- 必须使用与MongoDB4.2以上兼容的驱动
- 事务默认必须在 60 秒（可调） 内完成， 否则将被取消
- 设计事务的分片不能使用仲裁节点
- 事务会影响chunk迁移效率。 正在迁移的chunk 也可能造成事务提交失败（重试即可）
- 多文档事务中的读操作必须使用主节点读；
- readConcern只应该在事务级别设置， 不能设置在每次读写操作上。
